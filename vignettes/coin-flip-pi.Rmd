---
title: "Computing Pi by Flipping a Coin"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Computing Pi by Flipping a Coin}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
if (requireNamespace("coinpi", quietly = TRUE)) {
  library(coinpi)
} else {
  candidates <- c(
    file.path("R", "simulate_coin_pi.R"),
    file.path("..", "R", "simulate_coin_pi.R")
  )
  src <- candidates[file.exists(candidates)][1]
  if (is.na(src)) {
    stop("Cannot locate R/simulate_coin_pi.R for vignette fallback loading.")
  }
  source(src)
}
```

## Background

In the post
<https://statmodeling.stat.columbia.edu/2026/02/21/computing-pi-by-flipping-a-coin/>,
Andrew Gelman discusses a 2026 note by Jim Propp. The simulation rule is:

1. Flip a fair coin.
2. Keep flipping until heads first outnumber tails.
3. Record `H_tau / tau` for that trial (`H_tau` heads out of `tau` tosses).
4. Repeat and average.

The theorem in the note states that:

`E(H_tau / tau) = pi / 4`

so `4 * mean(H_tau / tau)` estimates `pi`.

## General Threshold View (`p` Instead of `1/2`)

The same stopping-time idea can be written with a threshold `p in (0, 1)`:

1. Stop at `tau_p = inf{n >= 1: H_n / n > p}`.
2. Record `R_p = H_{tau_p} / tau_p`.
3. Repeat and average.

Useful boundary cases:

- At `p = 0`, you stop at the first head, so `E[R_0] = log(2)`.
- At `p = 1/2`, Propp's result gives `E[R_{1/2}] = pi/4`.

For `p <= 1/2`, the crossing occurs almost surely, so repeated simulation is
straightforward. For `p > 1/2`, crossing has probability less than 1, so
simulations usually need conditioning on successful crossing (`tau_p < Inf`).

## Why Chunked Vectorization?

A direct `while` loop over one trial at a time is simple but slow in R. This
package instead:

1. Simulates many active trials at once in a vectorized chunk.
2. Updates heads/tosses/balance vectors for all active trials each step.
3. Drops completed trials and continues until the chunk is done.
4. Carries running sums to the next chunk so total memory stays bounded.

With `chunk_size = 1e6L`, the algorithm processes one million trial states at a
time, then folds those results into the global estimate before moving on.

## Basic Usage

```{r}
fit <- simulate_coin_pi(
  n_sims = 500L,
  chunk_size = 100L,
  seed = 123,
  progress = FALSE
)
fit
```

## Large Chunk Example

```{r, eval = FALSE}
# One million trial states per chunk
fit_big <- simulate_coin_pi(
  n_sims = 5e6L,
  chunk_size = 1e6L,
  seed = 2026,
  progress = TRUE
)
fit_big$pi_hat
```

## Returning Raw Ratios

```{r}
fit_ratios <- simulate_coin_pi(
  n_sims = 2000L,
  chunk_size = 500L,
  seed = 99,
  progress = FALSE,
  return_ratios = TRUE
)

summary(fit_ratios$ratios)
```
